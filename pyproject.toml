[project]
name = "model-workbench"
version = "0.1.0"
description = "Add your description here"
readme = "README.txt"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.12.0",
    "compressed-tensors>=0.9.0",  # Required for FP8 quantized models
    "fastapi==0.123.0",
    "httpx>=0.28.1",
    "huggingface-hub[cli]>=0.36.0",
    "openai>=1.0.0",  # For server benchmarking
    "pillow>=10.0.0",
    "pyyaml>=6.0.3",
    "requests>=2.32.5",
    "torch>=2.9.0",
    "transformers>=4.50.0",
    "uvicorn>=0.38.0",
    "vllm>=0.12.0",
]

# For models requiring nightly transformers/tokenizers (e.g., GLM-4.6V),
# use: uv sync --config config/nightly.toml --python-venv .venv-nightly
# Mark models with `nightly: true` in config/models.yaml
