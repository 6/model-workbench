[project]
name = "model-workbench"
version = "0.1.0"
description = "Add your description here"
readme = "README.txt"
requires-python = ">=3.12"
dependencies = [
    "accelerate>=1.12.0",
    "compressed-tensors>=0.9.0",  # Required for FP8 quantized models
    "datasets>=4.4.1",
    "deepeval>=2.0.0",  # For IFEval/HumanEval benchmarks
    "fastapi==0.123.0",
    "httpx>=0.28.1",
    "huggingface-hub[cli]>=0.36.0",
    "mistral-common>=1.8.6",
    "openai>=1.0.0",  # For server benchmarking
    "pandas>=2.3.3",
    "pillow>=10.0.0",
    "pyyaml>=6.0.3",
    "requests>=2.32.5",
    "torch>=2.9.0",
    "transformers>=4.50.0",
    "uvicorn>=0.38.0",
    "vllm>=0.12.0",
]

# For models requiring nightly transformers/tokenizers (e.g., GLM-4.6V),
# see nightly/pyproject.toml - run: (cd nightly && uv sync)
# Mark models with `nightly: true` in config/models.yaml

[dependency-groups]
dev = ["ruff>=0.14.0"]

[tool.ruff]
target-version = "py312"
line-length = 100

[tool.ruff.lint]
select = [
    "F",  # Pyflakes (F401 unused imports, F821 undefined names, etc.)
    "I",  # isort (import sorting)
]

[tool.ruff.lint.isort]
known-first-party = ["scripts"]
