# AWQ compression using vLLM base for version alignment
ARG VERSION=nightly
FROM vllm/vllm-openai:${VERSION}

# Install llmcompressor v0.9.0 WITHOUT upgrading deps (vLLM image has all required packages)
# --no-deps prevents transformers upgrade which breaks torch/torchvision compatibility
# Also install datasets for calibration data loading
RUN pip install --no-cache-dir --no-deps llmcompressor==0.9.0 && \
    pip install --no-cache-dir datasets

WORKDIR /workspace
