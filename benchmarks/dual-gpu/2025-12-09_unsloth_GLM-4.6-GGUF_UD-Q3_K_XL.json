{
  "timestamp": "2025-12-09_045625",
  "model_id": "unsloth/GLM-4.6-GGUF/UD-Q3_K_XL",
  "model_ref": "/home/peter/models/unsloth/GLM-4.6-GGUF/UD-Q3_K_XL/GLM-4.6-UD-Q3_K_XL-00001-of-00004.gguf",
  "engine": "llama-server",
  "gpu_info": {
    "driver_version": "580.95.05",
    "gpus": [
      {
        "index": 0,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887
      },
      {
        "index": 1,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887
      }
    ]
  },
  "gpu_memory": {
    "used_mib": 152048,
    "total_mib": 195774,
    "gpus": [
      {
        "index": 0,
        "used_mib": 75208,
        "total_mib": 97887
      },
      {
        "index": 1,
        "used_mib": 76840,
        "total_mib": 97887
      }
    ]
  },
  "tag": "dual-gpu",
  "env": {
    "CUDA_VISIBLE_DEVICES": "",
    "llama_server_bin": "/home/peter/llama.cpp/build/bin/llama-server",
    "host": "127.0.0.1",
    "port": 8080,
    "ctx": null,
    "n_gpu_layers": 999,
    "parallel": 1,
    "temperature": 0.0,
    "seed": 0
  },
  "bench": {
    "prompt_set": "short",
    "prompt": "Explain speculative decoding in 2 sentences.",
    "iterations": [
      {
        "wall_s": 1.1595286619995022,
        "ttft_ms": 19.783,
        "prompt_tokens": 1,
        "generated_tokens": 57,
        "tok_per_s": 49.15790516269659,
        "generation_tok_per_s": 50.63776937960737,
        "output_text": " Speculative decoding is a technique where a smaller, faster model generates candidate tokens, and a larger, more accurate model verifies and corrects them in a single pass. This approach speeds up inference by reducing the number of sequential steps required by the larger model while maintaining its output quality.",
        "extra": {
          "prompt_ms": 19.783,
          "generation_ms": 1125.642,
          "ms_per_token": 19.748105263157896
        }
      },
      {
        "wall_s": 1.1217852300032973,
        "ttft_ms": 19.66,
        "prompt_tokens": 1,
        "generated_tokens": 57,
        "tok_per_s": 50.81186529780969,
        "generation_tok_per_s": 52.12400758632924,
        "output_text": " Speculative decoding is a technique where a smaller, faster model generates candidate tokens, and a larger, more accurate model verifies and corrects them in a single pass. This approach speeds up inference by reducing the number of sequential steps required by the larger model while maintaining its output quality.",
        "extra": {
          "prompt_ms": 19.66,
          "generation_ms": 1093.546,
          "ms_per_token": 19.18501754385965
        }
      },
      {
        "wall_s": 1.1253823570004897,
        "ttft_ms": 19.634,
        "prompt_tokens": 1,
        "generated_tokens": 57,
        "tok_per_s": 50.64945229097385,
        "generation_tok_per_s": 52.078431945823816,
        "output_text": " Speculative decoding is a technique where a smaller, faster model generates candidate tokens, and a larger, more accurate model verifies and corrects them in a single pass. This approach speeds up inference by reducing the number of sequential steps required by the larger model while maintaining its output quality.",
        "extra": {
          "prompt_ms": 19.634,
          "generation_ms": 1094.503,
          "ms_per_token": 19.201807017543857
        }
      }
    ],
    "summary": {
      "iterations": 3,
      "median_tok_per_s": 50.64945229097385,
      "median_wall_s": 1.1253823570004897,
      "median_ttft_ms": 19.66,
      "median_generated_tokens": 57,
      "median_generation_tok_per_s": 52.078431945823816
    }
  }
}