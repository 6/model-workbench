{
  "timestamp": "2025-12-07_210556",
  "model_id": "openai/gpt-oss-safeguard-20b",
  "model_ref": "openai/gpt-oss-safeguard-20b",
  "engine": "vllm",
  "gpu_info": {
    "driver_version": "580.95.05",
    "gpus": [
      {
        "index": 0,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887
      },
      {
        "index": 1,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887
      }
    ]
  },
  "tag": "dual-gpu",
  "env": {
    "CUDA_VISIBLE_DEVICES": "",
    "engine": "vllm",
    "dtype": "auto",
    "max_model_len": null,
    "gpu_memory_utilization": 0.9,
    "temperature": 0.0,
    "seed": 0,
    "vary_seed": false
  },
  "bench": {
    "prompt_set": "long",
    "prompt": "Write a concise technical overview of KV cache and why it matters for long context.",
    "iterations": [
      {
        "wall_s": 2.085616103000575,
        "max_tokens": 512,
        "prompt_tokens": 16,
        "generated_tokens": 512,
        "tok_per_s": 245.49100827491014,
        "temperature": 0.0,
        "seed": 0,
        "output_text": "\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from scratch.\n\nThe KV cache is particularly useful for long context, as it allows the model to efficiently store and retrieve a large number of tokens. This is important because language models often need to process long sequences of text, and the KV cache allows the model to do this efficiently without having to recompute the entire sequence each time.\n\nIn summary, the KV cache is a key-value store that allows language models to efficiently store and retrieve previously generated tokens, which is particularly useful for long context.\n\nKV\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from"
      },
      {
        "wall_s": 2.0809052829990833,
        "max_tokens": 512,
        "prompt_tokens": 16,
        "generated_tokens": 512,
        "tok_per_s": 246.04675867903285,
        "temperature": 0.0,
        "seed": 0,
        "output_text": "\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from scratch.\n\nThe KV cache is particularly useful for long context, as it allows the model to efficiently store and retrieve a large number of tokens. This is important because language models often need to process long sequences of text, and the KV cache allows the model to do this efficiently without having to recompute the entire sequence each time.\n\nIn summary, the KV cache is a key-value store that allows language models to efficiently store and retrieve previously generated tokens, which is particularly useful for long context.\n\nKV\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from"
      },
      {
        "wall_s": 2.08384762499918,
        "max_tokens": 512,
        "prompt_tokens": 16,
        "generated_tokens": 512,
        "tok_per_s": 245.69934665938038,
        "temperature": 0.0,
        "seed": 0,
        "output_text": "\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from scratch.\n\nThe KV cache is particularly useful for long context, as it allows the model to efficiently store and retrieve a large number of tokens. This is important because language models often need to process long sequences of text, and the KV cache allows the model to do this efficiently without having to recompute the entire sequence each time.\n\nIn summary, the KV cache is a key-value store that allows language models to efficiently store and retrieve previously generated tokens, which is particularly useful for long context.\n\nKV\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that\n\nThe KV cache is a mechanism used in language models to store and retrieve previously generated tokens. It is a key-value store that maps a unique identifier (the key) to a specific token (the value). The KV cache is used to store the tokens generated by the model during inference, and it allows the model to quickly retrieve the tokens it has already generated, rather than having to recompute them from"
      }
    ],
    "summary": {
      "iterations": 3,
      "median_wall_s": 2.08384762499918,
      "median_generated_tokens": 512,
      "median_tok_per_s": 245.69934665938038
    }
  }
}