{
  "timestamp": "2025-12-09_055501",
  "repo_id": "unsloth/GLM-4.6-GGUF",
  "model_ref": "~/models/unsloth/GLM-4.6-GGUF/IQ4_XS/GLM-4.6-IQ4_XS-00001-of-00004.gguf",
  "engine": "llama-server",
  "gpu_info": {
    "driver_version": "580.95.05",
    "gpus": [
      {
        "index": 0,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887,
        "pcie_gen": 5,
        "pcie_width": 8,
        "memory_used_mib": 90232
      },
      {
        "index": 1,
        "name": "NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition",
        "memory_total_mib": 97887,
        "pcie_gen": 5,
        "pcie_width": 8,
        "memory_used_mib": 92434
      }
    ],
    "memory_used_mib": 182666,
    "memory_total_mib": 195774
  },
  "env": {
    "CUDA_VISIBLE_DEVICES": "",
    "llama_server_bin": "~/llama.cpp/build/bin/llama-server",
    "host": "127.0.0.1",
    "port": 8080,
    "ctx": null,
    "n_gpu_layers": 999,
    "parallel": 1,
    "temperature": 0.0,
    "seed": 0
  },
  "bench": {
    "prompt_set": "short",
    "prompt": "Explain speculative decoding in 2 sentences.",
    "iterations": [
      {
        "wall_s": 1.1727534029996605,
        "prompt_tokens": 9,
        "generated_tokens": 61,
        "ttft_ms": 18.813,
        "tok_per_s": 52.0143449117049,
        "generation_tok_per_s": 53.27352724897251,
        "generation_ms": 1145.034,
        "output_text": " Speculative decoding is a technique where a smaller, faster \"draft\" model generates candidate tokens, which are then verified by a larger, more accurate \"target\" model. This approach speeds up inference by reducing the number of times the larger model needs to run, while maintaining the quality of its outputs."
      },
      {
        "wall_s": 1.1632255590011482,
        "prompt_tokens": 9,
        "generated_tokens": 61,
        "ttft_ms": 18.811,
        "tok_per_s": 52.44038830472413,
        "generation_tok_per_s": 53.73620807364504,
        "generation_ms": 1135.175,
        "output_text": " Speculative decoding is a technique where a smaller, faster \"draft\" model generates candidate tokens, which are then verified by a larger, more accurate \"target\" model. This approach speeds up inference by reducing the number of times the larger model needs to run, while maintaining the quality of its outputs."
      },
      {
        "wall_s": 1.1444916629989166,
        "prompt_tokens": 9,
        "generated_tokens": 61,
        "ttft_ms": 18.831,
        "tok_per_s": 53.298771823432446,
        "generation_tok_per_s": 54.26032502824205,
        "generation_ms": 1124.21,
        "output_text": " Speculative decoding is a technique where a smaller, faster \"draft\" model generates candidate tokens, which are then verified by a larger, more accurate \"target\" model. This approach speeds up inference by reducing the number of times the larger model needs to run, while maintaining the quality of its outputs."
      }
    ],
    "summary": {
      "iterations": 3,
      "median_tok_per_s": 52.44038830472413,
      "median_wall_s": 1.1632255590011482,
      "median_ttft_ms": 18.813,
      "median_generation_tok_per_s": 53.73620807364504
    }
  },
  "mode": "text-only"
}
